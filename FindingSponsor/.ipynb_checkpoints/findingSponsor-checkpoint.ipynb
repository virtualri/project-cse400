{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the sponsor from employee list\n",
    "# Title: To Allocate resources\n",
    "#\n",
    "# CSE 400 - Dissertation: Implementation and Results\n",
    "# Student    : Rashadul Islam\n",
    "# Id         : 0301175301\n",
    "# Department : Department of CSE\n",
    "# Semester   : Spring 2019\n",
    "# Written on : Wed Sep 10 10:00:00 BST 2019\n",
    "#\n",
    "\n",
    "# Library\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset as train and test as input \n",
    "train=pd.read_csv('sales-per-employee.csv')\n",
    "test=pd.read_csv('employee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/pandas/core/frame.py:4097: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# Preparing Dataset \n",
    "number = preprocessing.LabelEncoder()\n",
    "\n",
    "# Based on OEE_score finding the most possible sponsor from the employees \n",
    "train['OEE_score'] = np.sqrt(train['OEE_score'])\n",
    "test['OEE_score'] = np.sqrt(test['OEE_score'])\n",
    "\n",
    "test['Profit'] = 0\n",
    "\n",
    "combi = train.append(test)\n",
    "\n",
    "col = ['Room_Status']\n",
    "for i in col:\n",
    " combi[i] = number.fit_transform(combi[i].astype('str'))\n",
    " combi[i] = combi[i].astype('object')\n",
    "\n",
    "train = combi[:train.shape[0]]\n",
    "test = combi[train.shape[0]:]\n",
    "test.drop('Profit',axis=1,inplace=True)\n",
    "\n",
    "# dataset preparation for tpot\n",
    "tpot_train = train.drop(['Employee id'],axis=1)\n",
    "tpot_test = test.drop(['Employee id'],axis=1)\n",
    "tpot_train = train.drop(['Employee name','Room_Status'],axis=1)\n",
    "tpot_test = test.drop(['Employee name','Room_Status'],axis=1)\n",
    "target = tpot_train['Profit']\n",
    "tpot_train.drop('Profit',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 operators have been imported by TPOT.\n",
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=10100, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 24.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-487812094.2537516\tRidgeCV(Normalizer(input_matrix, Normalizer__norm=l1))\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 55.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-487812094.2537516\tRidgeCV(Normalizer(input_matrix, Normalizer__norm=l1))\n",
      "-3\t-472642806.3385912\tXGBRegressor(SelectPercentile(MinMaxScaler(input_matrix), SelectPercentile__percentile=12), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:52:07] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 41.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-472642806.3385912\tXGBRegressor(SelectPercentile(input_matrix, SelectPercentile__percentile=12), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 4 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-472642806.3385912\tXGBRegressor(SelectPercentile(input_matrix, SelectPercentile__percentile=12), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-468362475.0547139\tLassoLarsCV(Normalizer(Normalizer(input_matrix, Normalizer__norm=max), Normalizer__norm=l2), LassoLarsCV__normalize=False)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 5 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-472642806.3385912\tXGBRegressor(SelectPercentile(input_matrix, SelectPercentile__percentile=12), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-468362475.0547139\tLassoLarsCV(Normalizer(Normalizer(input_matrix, Normalizer__norm=max), Normalizer__norm=l2), LassoLarsCV__normalize=False)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 33.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 58.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 6 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-447371438.2122947\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required by MinMaxScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _mate_operator: num_test=0 [18:54:06] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 55.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 7 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-447371438.2122947\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "Generation 8 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-447371438.2122947\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-443957470.2426613\tLassoLarsCV(SelectPercentile(Normalizer(input_matrix, Normalizer__norm=l2), SelectPercentile__percentile=25), LassoLarsCV__normalize=False)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 48.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 52.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:54:53] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _mate_operator: num_test=0 [18:54:54] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _mate_operator: num_test=1 [18:54:54] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _mate_operator: num_test=2 [18:54:54] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Generation 9 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-447371438.2122947\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-443957470.2426613\tLassoLarsCV(SelectPercentile(Normalizer(input_matrix, Normalizer__norm=l2), SelectPercentile__percentile=25), LassoLarsCV__normalize=False)\n",
      "-4\t-443533094.6903035\tLassoLarsCV(StandardScaler(SelectPercentile(Normalizer(input_matrix, Normalizer__norm=l2), SelectPercentile__percentile=25)), LassoLarsCV__normalize=False)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 96.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:55:10] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 76.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:55:13] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 10 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 59.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 29.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _mate_operator: num_test=0 [18:55:30] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _mate_operator: num_test=1 [18:55:30] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _mate_operator: num_test=2 [18:55:30] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _mate_operator: num_test=1 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 52.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 11 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.\n",
      "_pre_test decorator: _mate_operator: num_test=0 [18:55:56] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _mate_operator: num_test=0 [18:55:58] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _mate_operator: num_test=1 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 100.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 12 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 26.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 96.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:56:16] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _mate_operator: num_test=0 [18:56:17] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _mate_operator: num_test=1 [18:56:17] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 13 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:56:33] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.01000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 14 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _mate_operator: num_test=0 [18:56:48] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _mate_operator: num_test=1 [18:56:48] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _mate_operator: num_test=2 [18:56:48] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 100.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 96.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:56:51] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 15 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-427976571.33706\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 41.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 78.\n",
      "_pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.01000.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 16 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-427976571.33706\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:57:26] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:57:27] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:57:28] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:57:29] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Generation 17 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-427976571.33706\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:57:46] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:57:46] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:57:46] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 67.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 57.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 18 - Current Pareto front scores:\n",
      "-1\t-489232577.44958955\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-427976571.33706\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:57:58] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 36.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 19 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-427976571.33706\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-5\t-424440970.1228043\tLassoLarsCV(SelectPercentile(Normalizer(OneHotEncoder(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.15, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), Normalizer__norm=l2), SelectPercentile__percentile=33), LassoLarsCV__normalize=False)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:58:15] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:58:16] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:58:16] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 44.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 20 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-427976571.33706\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-5\t-424440970.1228043\tLassoLarsCV(SelectPercentile(Normalizer(OneHotEncoder(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.15, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), Normalizer__norm=l2), SelectPercentile__percentile=33), LassoLarsCV__normalize=False)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 89.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 73.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.00500.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 21 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-427976571.33706\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-402503962.13753355\tXGBRegressor(ZeroCount(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005)), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 86.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:58:52] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 22 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-402503962.13753355\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 30.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [18:59:06] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 55.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 23 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-402503962.13753355\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 28.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 53.\n",
      "_pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _mate_operator: num_test=1 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "Generation 24 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-402503962.13753355\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 72.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 25 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-434768122.6394041\tXGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-3\t-402503962.13753355\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "Generation 26 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-402503962.13753355\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:00:14] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 99.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 27 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-399829152.69193137\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Generation 28 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-399829152.69193137\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:00:49] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 61.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 41.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:00:52] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Generation 29 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-399829152.69193137\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:01:06] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 75.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 29.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:01:07] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 66.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "Generation 30 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-399829152.69193137\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 33.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 72.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "Generation 31 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-399829152.69193137\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:01:40] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 99.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "Generation 32 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-399829152.69193137\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.0005), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 67.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 45.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:01:58] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Generation 33 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-399829152.69193137\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-397276233.05084544\tXGBRegressor(VarianceThreshold(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.01), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.0005), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:02:08] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 68.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:02:09] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "Generation 34 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-399829152.69193137\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-396890601.7750039\tXGBRegressor(KNeighborsRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), KNeighborsRegressor__n_neighbors=17, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.0005), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:02:19] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 94.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "Generation 35 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-399829152.69193137\tXGBRegressor(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=1.0, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 81.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:02:39] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 50.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Generation 36 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-397276233.05084544\tXGBRegressor(VarianceThreshold(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.01), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:02:53] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 76.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 36.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "Generation 37 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-397276233.05084544\tXGBRegressor(VarianceThreshold(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.01), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 82.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 59.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.01000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 38 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-397276233.05084544\tXGBRegressor(VarianceThreshold(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.01), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 64.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:03:27] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 86.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 39 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-397276233.05084544\tXGBRegressor(VarianceThreshold(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.01), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 55.\n",
      "Generation 40 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-396925683.07801145\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 23.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 52.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 43.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Generation 41 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-394135843.6497773\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=poly, Nystroem__n_components=6), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 80.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 55.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 42 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-394135843.6497773\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=poly, Nystroem__n_components=6), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-6\t-387193954.39405906\tXGBRegressor(LinearSVR(VarianceThreshold(VarianceThreshold(Nystroem(CombineDFs(RobustScaler(input_matrix), input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.0005), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 43 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-394135843.6497773\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=poly, Nystroem__n_components=6), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-6\t-387193954.39405906\tXGBRegressor(LinearSVR(VarianceThreshold(VarianceThreshold(Nystroem(CombineDFs(RobustScaler(input_matrix), input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.0005), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 44 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-394135843.6497773\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=poly, Nystroem__n_components=6), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-6\t-387193954.39405906\tXGBRegressor(LinearSVR(VarianceThreshold(VarianceThreshold(Nystroem(CombineDFs(RobustScaler(input_matrix), input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.0005), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 95.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.00050.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 81.\n",
      "Generation 45 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-394135843.6497773\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=poly, Nystroem__n_components=6), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-388931656.6246444\tXGBRegressor(LinearSVR(VarianceThreshold(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-6\t-387193954.39405906\tXGBRegressor(LinearSVR(VarianceThreshold(VarianceThreshold(Nystroem(CombineDFs(RobustScaler(input_matrix), input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=8), VarianceThreshold__threshold=0.0005), VarianceThreshold__threshold=0.005), LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 65.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 77.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 54.\n",
      "Generation 46 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-394135843.6497773\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=poly, Nystroem__n_components=6), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 71.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 99.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:05:46] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:05:46] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:05:47] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 59.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 47 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-394135843.6497773\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=poly, Nystroem__n_components=6), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 67.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 59.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:06:01] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Generation 48 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-394135843.6497773\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=poly, Nystroem__n_components=6), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 65.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 68.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 82.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 49 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-394135843.6497773\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=poly, Nystroem__n_components=6), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 100.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.00500.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 29.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 50 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-384224493.9756363\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:06:43] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 88.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 51 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-384224493.9756363\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 85.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Generation 52 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-384224493.9756363\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 54.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 57.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 94.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 60.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 53 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:07:26] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:07:26] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 87.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 54 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 31.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:07:40] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:07:40] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:07:41] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 62.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 55 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Generation 56 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:08:09] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:08:11] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:08:13] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:08:13] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 57 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-374811898.6076356\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.35000000000000003, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 93.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:08:29] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 58 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-372200268.7858482\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.05, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:08:41] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:08:43] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 59 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-372200268.7858482\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.05, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:09:00] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:09:01] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 60 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-372200268.7858482\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.05, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 67.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 59.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 61 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-372200268.7858482\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.05, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:09:32] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:09:34] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 62 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-372200268.7858482\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.05, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 77.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 63 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-372200268.7858482\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.05, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 88.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:10:07] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 79.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 64 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-372200268.7858482\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.05, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:10:23] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 72.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 [19:10:25] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 65 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-372200268.7858482\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.05, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:10:43] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 66 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-372200268.7858482\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.05, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:10:59] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 31.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 93.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:11:01] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:11:02] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 67 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 50.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 68 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:11:36] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:11:37] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:11:37] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 37.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 69 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:11:52] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 38.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:11:53] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:11:54] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 70 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 71 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 54.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 22.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 72 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:12:44] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 87.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 39.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 46.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 73 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 93.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:13:05] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 63.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 74 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-349058914.203693\tXGBRegressor(KNeighborsRegressor(PCA(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 75 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-349058914.203693\tXGBRegressor(KNeighborsRegressor(PCA(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 27.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 76 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-349058914.203693\tXGBRegressor(KNeighborsRegressor(PCA(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 100.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:13:53] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:13:54] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 77 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-349058914.203693\tXGBRegressor(KNeighborsRegressor(PCA(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:14:11] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:14:11] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 78 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-349058914.203693\tXGBRegressor(KNeighborsRegressor(PCA(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 76.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 91.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:14:29] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 33.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 74.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 79 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-349058914.203693\tXGBRegressor(KNeighborsRegressor(PCA(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 80 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-349058914.203693\tXGBRegressor(KNeighborsRegressor(PCA(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 67.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 80.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 [19:15:01] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 81 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-349058914.203693\tXGBRegressor(KNeighborsRegressor(PCA(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 87.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 82 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-353334805.09791833\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-5\t-349058914.203693\tXGBRegressor(KNeighborsRegressor(PCA(PCA(Nystroem(input_matrix, Nystroem__gamma=0.5, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=8, PCA__svd_solver=randomized), PCA__iterated_power=2, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 28.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 56.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 [19:15:28] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:15:28] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:15:29] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:15:30] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 83 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-337690925.65226775\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=6), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 56.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:15:45] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 84 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 50.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 70.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 85 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:16:12] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 86 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 79.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 39.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:16:30] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 53.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 87 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 49.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 27.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 84.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 88 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 71.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 85.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:17:08] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 88.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 63.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:17:09] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 89 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 47.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:17:26] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:17:26] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 90 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:17:41] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 59.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:17:41] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 98.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 91 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 75.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 98.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 88.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:17:58] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 92 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:18:11] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 93 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 46.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:18:26] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 94 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:18:45] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 85.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "Generation 95 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 99.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 77.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 96 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 23.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 21.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 97 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:19:34] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:19:36] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 98 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 53.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:19:52] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 87.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 78.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 90.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:19:54] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 99 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 87.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 23.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 86.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [19:20:11] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 [19:20:11] /workspace/src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f04b3bcecb4]\n",
      "  [bt] (1) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::LazyInitModel()+0x5bf) [0x7f04b3c641ef]\n",
      "  [bt] (2) /usr/local/lib/python3.7/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x52) [0x7f04b3bcbac2]\n",
      "  [bt] (3) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f04f80b6ace]\n",
      "  [bt] (4) /lib64/libffi.so.6(ffi_call+0x35f) [0x7f04f80b648f]\n",
      "  [bt] (5) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x601) [0x7f04f80edfa1]\n",
      "  [bt] (6) /usr/lib64/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x1371f) [0x7f04f80ee71f]\n",
      "  [bt] (7) /lib64/libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0x4dc) [0x7f0506dca25c]\n",
      "  [bt] (8) /lib64/libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x5b25) [0x7f0506e1b135]\n",
      "\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(20, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 33.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 20, n_neighbors = 26.\n",
      "Generation 100 - Current Pareto front scores:\n",
      "-1\t-459307755.10204077\tKNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=7, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)\n",
      "-2\t-417007525.9173352\tXGBRegressor(Nystroem(CombineDFs(input_matrix, input_matrix), Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=6), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-3\t-383382314.925002\tXGBRegressor(KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.75, Nystroem__kernel=cosine, Nystroem__n_components=9), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "-4\t-323748414.13616216\tXGBRegressor(KNeighborsRegressor(PCA(Nystroem(input_matrix, Nystroem__gamma=0.65, Nystroem__kernel=cosine, Nystroem__n_components=5), PCA__iterated_power=1, PCA__svd_solver=randomized), KNeighborsRegressor__n_neighbors=12, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=distance), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0)\n",
      "\n",
      "Cross validation score\n",
      "Imputing missing values in feature set\n",
      "-1123334812.1166809\n"
     ]
    }
   ],
   "source": [
    "# To automate the machine learning\n",
    "# to optimizes machine learning pipelines using genetic programming\n",
    "# through optimization\n",
    "\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tpot_train, target,\n",
    " train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Genetic Algorithm \n",
    "# to find the model\n",
    "# please insert as more generations and population size to get the \n",
    "# appropriate Cross Validation (C V) Score for model validation\n",
    "\n",
    "# Pipeline optimizer\n",
    "\n",
    "# to get the sample estimate model faster \n",
    "#tpot = TPOTRegressor(generations=10, population_size=100, verbosity=3)\n",
    "\n",
    "# most suitable optimizer\n",
    "tpot = TPOTRegressor(verbosity=3,cv=5)\n",
    "\n",
    "# Learning and predicting\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Estimate error or loss\n",
    "print (\"Cross validation score\")\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/lib64/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profit</th>\n",
       "      <th>Employee id</th>\n",
       "      <th>Employee name</th>\n",
       "      <th>OEE_score</th>\n",
       "      <th>Client_Stays</th>\n",
       "      <th>Room_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33856.171875</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>11.658902</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>78043.109375</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>11.349890</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>86519.812500</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64341.546875</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>10.115335</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>66896.578125</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>9.812747</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>89911.523438</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>9.222798</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69844.765625</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>8.929726</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43405.980469</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>8.790904</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7170.432617</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>8.716651</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55653.246094</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>8.563294</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7491.462891</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>8.482335</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59657.664062</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>8.472308</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>48032.128906</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>8.397619</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39854.070312</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>8.397619</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58625.007812</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>8.315047</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>62925.761719</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>8.315047</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25633.154297</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>8.266196</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>41619.679688</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>8.241359</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30250.515625</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>8.173127</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5853.250000</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>8.173127</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31230.335938</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>8.111104</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42249.714844</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>7.955501</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47951.058594</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>7.905694</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29740.800781</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>7.658329</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3327.603271</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>7.485987</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18272.316406</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>7.310267</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15386.392578</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>7.023532</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11633.487305</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>6.834471</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30559.947266</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>6.403905</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Profit  Employee id Employee name  OEE_score  Client_Stays  \\\n",
       "8   33856.171875            1             A  11.658902          31.0   \n",
       "26  78043.109375            5             D  11.349890          27.0   \n",
       "23  86519.812500            4             C  10.900000          24.0   \n",
       "7   64341.546875            1             A  10.115335          20.0   \n",
       "16  66896.578125            3             B   9.812747          22.0   \n",
       "27  89911.523438            5             D   9.222798          15.0   \n",
       "0   69844.765625            1             A   8.929726          10.0   \n",
       "6   43405.980469            1             A   8.790904          15.0   \n",
       "3    7170.432617            1             A   8.716651           7.0   \n",
       "10  55653.246094            2             B   8.563294           8.0   \n",
       "13   7491.462891            2             B   8.482335           7.0   \n",
       "5   59657.664062            1             A   8.472308          10.0   \n",
       "25  48032.128906            5             D   8.397619           8.0   \n",
       "14  39854.070312            3             B   8.397619           8.0   \n",
       "1   58625.007812            1             A   8.315047           9.0   \n",
       "20  62925.761719            4             C   8.315047           9.0   \n",
       "21  25633.154297            4             C   8.266196           4.0   \n",
       "22  41619.679688            4             C   8.241359           7.0   \n",
       "17  30250.515625            3             B   8.173127           5.0   \n",
       "28   5853.250000            5             D   8.173127           5.0   \n",
       "11  31230.335938            2             B   8.111104           3.0   \n",
       "9   42249.714844            2             B   7.955501           6.0   \n",
       "2   47951.058594            1             A   7.905694           8.0   \n",
       "12  29740.800781            2             B   7.658329           5.0   \n",
       "18   3327.603271            3             B   7.485987           4.0   \n",
       "15  18272.316406            3             B   7.310267           3.0   \n",
       "24  15386.392578            5             D   7.023532           3.0   \n",
       "19  11633.487305            4             C   6.834471           2.0   \n",
       "4   30559.947266            1             A   6.403905           6.0   \n",
       "\n",
       "   Room_Status  \n",
       "8            1  \n",
       "26           0  \n",
       "23           3  \n",
       "7            2  \n",
       "16           0  \n",
       "27           2  \n",
       "0            5  \n",
       "6            0  \n",
       "3            3  \n",
       "10           5  \n",
       "13           3  \n",
       "5            2  \n",
       "25           2  \n",
       "14           4  \n",
       "1            2  \n",
       "20           5  \n",
       "21           2  \n",
       "22           2  \n",
       "17           2  \n",
       "28           1  \n",
       "11           2  \n",
       "9            5  \n",
       "2            2  \n",
       "12           2  \n",
       "18           1  \n",
       "15           2  \n",
       "24           4  \n",
       "19           5  \n",
       "4            4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "tpot_pred = tpot.predict(tpot_test)\n",
    "\n",
    "# Results\n",
    "final = pd.DataFrame(data=tpot_pred)\n",
    "final = final.rename(columns = {'0':'Profit'})\n",
    "final['Employee id'] = test['Employee id']\n",
    "final['Employee name'] = test['Employee name']\n",
    "final['OEE_score'] = test['OEE_score']\n",
    "final['Client_Stays'] = test['Client_Stays']\n",
    "final['Room_Status'] = test['Room_Status']\n",
    "final.columns = ['Profit','Employee id','Employee name','OEE_score','Client_Stays','Room_Status']\n",
    "final.sort_values(by=['OEE_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Profit  Employee id Employee name  OEE_score  Client_Stays  \\\n",
      "0   69844.765625            1             A   8.929726          10.0   \n",
      "1   58625.007812            1             A   8.315047           9.0   \n",
      "2   47951.058594            1             A   7.905694           8.0   \n",
      "3    7170.432617            1             A   8.716651           7.0   \n",
      "4   30559.947266            1             A   6.403905           6.0   \n",
      "5   59657.664062            1             A   8.472308          10.0   \n",
      "6   43405.980469            1             A   8.790904          15.0   \n",
      "7   64341.546875            1             A  10.115335          20.0   \n",
      "8   33856.171875            1             A  11.658902          31.0   \n",
      "9   42249.714844            2             B   7.955501           6.0   \n",
      "10  55653.246094            2             B   8.563294           8.0   \n",
      "11  31230.335938            2             B   8.111104           3.0   \n",
      "12  29740.800781            2             B   7.658329           5.0   \n",
      "13   7491.462891            2             B   8.482335           7.0   \n",
      "14  39854.070312            3             B   8.397619           8.0   \n",
      "15  18272.316406            3             B   7.310267           3.0   \n",
      "16  66896.578125            3             B   9.812747          22.0   \n",
      "17  30250.515625            3             B   8.173127           5.0   \n",
      "18   3327.603271            3             B   7.485987           4.0   \n",
      "19  11633.487305            4             C   6.834471           2.0   \n",
      "20  62925.761719            4             C   8.315047           9.0   \n",
      "21  25633.154297            4             C   8.266196           4.0   \n",
      "22  41619.679688            4             C   8.241359           7.0   \n",
      "23  86519.812500            4             C  10.900000          24.0   \n",
      "24  15386.392578            5             D   7.023532           3.0   \n",
      "25  48032.128906            5             D   8.397619           8.0   \n",
      "26  78043.109375            5             D  11.349890          27.0   \n",
      "27  89911.523438            5             D   9.222798          15.0   \n",
      "28   5853.250000            5             D   8.173127           5.0   \n",
      "\n",
      "   Room_Status Sponsor  \n",
      "0            5     NaN  \n",
      "1            2     NaN  \n",
      "2            2     NaN  \n",
      "3            3     NaN  \n",
      "4            4     NaN  \n",
      "5            2     NaN  \n",
      "6            0     NaN  \n",
      "7            2     NaN  \n",
      "8            1     NaN  \n",
      "9            5     NaN  \n",
      "10           5     NaN  \n",
      "11           2     NaN  \n",
      "12           2     NaN  \n",
      "13           3     NaN  \n",
      "14           4     NaN  \n",
      "15           2     NaN  \n",
      "16           0     NaN  \n",
      "17           2     NaN  \n",
      "18           1     NaN  \n",
      "19           5     NaN  \n",
      "20           5     NaN  \n",
      "21           2     NaN  \n",
      "22           2     NaN  \n",
      "23           3     NaN  \n",
      "24           4     NaN  \n",
      "25           2     NaN  \n",
      "26           0     NaN  \n",
      "27           2     NaN  \n",
      "28           1     NaN  \n"
     ]
    }
   ],
   "source": [
    "# Sponsor details based on possible sales over the client as profit\n",
    "final['Sponsor'] = final.loc[final[['Profit','OEE_score']].idxmax()[1]]\n",
    "print (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profit           33856.2\n",
       "Employee id            1\n",
       "Employee name          A\n",
       "OEE_score        11.6589\n",
       "Client_Stays          31\n",
       "Room_Status            1\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sponsor may be\n",
    "final.loc[final[['Profit','OEE_score']].idxmax()[1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
